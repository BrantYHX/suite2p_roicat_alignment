[{"type_name": "list", "function_load": "def load_folder(\n    path: Union[str, Path],\n    type_lookup: Dict,\n    check: bool = True,\n    **kwargs,\n) -> Any:\n    \"\"\"\n    Loads the folder from the given path. Used for types: list, tuple, set, frozenset, dict.\n    \"\"\"\n    metadata = load_folder_metadata(path_dir=path, name_metadata=FILENAME_METADATA, check=check)\n\n    if check:\n        names_path_elements = [p.name for p in Path(path).iterdir() if (p.name != FILENAME_METADATA) and (p.name != FILENAME_TYPELOOKUP)]\n        # Check that index values are unique\n        indices = [value[\"index\"] for value in metadata[\"elements\"].values()]\n        if len(indices) != len(set(indices)):\n            raise ValueError(\"Indices in metadata are not unique.\")\n        \n        elif metadata[\"library\"] == \"python\":\n            if not is_version_compatible(version=metadata[\"version\"], rules=PYTHON_VERSIONS_SUPPORTED):\n                raise ValueError(f\"Python version '{metadata['version']}' not supported for library 'python' and type '{metadata['type']}'. Version rules: {PYTHON_VERSIONS_SUPPORTED}\")\n        else:\n            raise ValueError(\"Only 'python' library supported for container types.\")\n        \n    ## Sort the element names by their index\n    names_meta_sorted = _sort_element_names_by_index(metadata=metadata, check=check)\n    names_allowed = set(names_meta_sorted) | set(NAMES_EXTRA_FILES_ALLOWED)\n\n    if check:\n        # Check that all elements in metadata are present in the folder and vice versa\n        if not all(name in names_path_elements for name in names_meta_sorted):\n            missing_elements = set(names_meta_sorted) - set(names_path_elements)\n            raise FileNotFoundError(f\"Elements in metadata not found in folder: {missing_elements}, names_meta: {names_meta_sorted}, names_path: {names_path_elements}, path: {path}\")\n        if not all(name in names_allowed for name in names_path_elements):\n            extra_elements = set(names_path_elements) - set(names_allowed)\n            raise ValueError(f\"Extra elements in folder not found in metadata: {extra_elements}\")        \n\n    ## Load each element in the order specified by the metadata index\n    elements = [load_element(\n        path=str(Path(path) / name),\n        metadata=metadata[\"elements\"][name],\n        type_lookup=type_lookup,\n        check=check,\n    ) for name in names_meta_sorted]\n    \n    if metadata[\"type\"] == \"list\":\n        pass\n    elif metadata[\"type\"] == \"tuple\":\n        elements = tuple(elements)\n    elif metadata[\"type\"] == \"set\":\n        elements = set(elements)\n    elif metadata[\"type\"] == \"frozenset\":\n        elements = frozenset(elements)\n    elif metadata[\"type\"] == \"dict_item\":\n        ## Make sure that there are exactly 2 elements\n        if check:\n            if len(elements) != 2:\n                raise ValueError(f\"DictItem must contain exactly 2 elements. Found {len(elements)}.\")\n        elements = DictItem(key=elements[0], value=elements[1])\n    else:  ## elif metadata[\"type\"] == \"dict\"\n        ## Make sure that all elements are DictItem types\n        if check:\n            if not all(isinstance(element, DictItem) for element in elements):\n                raise TypeError(\"All elements in a dict must be of type DictItem.\")\n        try:\n            elements = {element.key: element.value for element in elements}  ## Unpack the DictItems\n        except AttributeError as e:\n            raise ValueError(f\"Error unpacking dict items: {e}\")\n    \n    return elements\n", "function_save": "def save_container(\n    obj: Union[list, tuple, set, dict, frozenset, 'DictItem'],\n    path: Union[str, Path],\n    type_name: str,\n    type_lookup: Dict,\n    check: bool = True,\n    overwrite: bool = False,\n    name_dict_items: bool = True,\n) -> None:\n    \"\"\"\n    Saves a list, tuple, set, frozenset, or dict_item to the given directory.\n    \"\"\"\n    if isinstance(obj, dict):\n        _check_case_only_sibling_keys(obj=obj) if check and (name_dict_items) else None \n        obj = [DictItem(key=key, value=value) for key, value in obj.items()]\n\n    metadata_elements = {}\n    for idx, element in enumerate(obj):\n        try:\n            props = type_lookup[type(element)]\n            type_element = props[\"type_name\"]            \n        except TypeError as e:\n            raise TypeError(f\"Failed to get properties for element. \\n Directory: {path}. \\n Index: {idx}. \\n element: {element}. \\n type_name: {type_name}. \\n Error: {e}\")\n        name_element = f\"{idx}.{props['suffix']}\"  ## Make name the index and add suffix\n        if name_dict_items:\n            if type_element == \"dict_item\":\n                if isinstance(element.key, str):\n                    name_element = f\"{element.key}.{props['suffix']}\"\n            elif type_name == \"dict_item\":\n                name_element = f\"{['key', 'value'][idx]}.{props['suffix']}\"\n\n        _check_filename_safety(name=name_element, warn=True, raise_error=False)\n        path_element = str(Path(path) / name_element)  ## Make path\n        save_object(\n            obj=element,\n            path=path_element,\n            check=check,\n            overwrite=overwrite,\n            type_lookup=type_lookup,\n        )\n        metadata_elements[name_element] = {\n            \"type\": type_element,\n            \"library\": props[\"library\"],\n            \"version\": _get_library_version(library=props[\"library\"]),\n            \"index\": idx,\n        }\n\n    metadata_container = {\n        \"elements\": metadata_elements,\n        \"type\": type_name,\n        \"library\": \"python\",\n        \"version\": _get_python_version(),\n        \"version_richfile\": VERSION_RICHFILE,\n    }\n    save_metadata(\n        metadata=metadata_container,\n        path_dir=path,\n        check=check,\n        name_metadata=FILENAME_METADATA,\n        overwrite=overwrite,\n    )\n", "object_class": "<class 'list'>", "suffix": "list", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "tuple", "function_load": "def load_folder(\n    path: Union[str, Path],\n    type_lookup: Dict,\n    check: bool = True,\n    **kwargs,\n) -> Any:\n    \"\"\"\n    Loads the folder from the given path. Used for types: list, tuple, set, frozenset, dict.\n    \"\"\"\n    metadata = load_folder_metadata(path_dir=path, name_metadata=FILENAME_METADATA, check=check)\n\n    if check:\n        names_path_elements = [p.name for p in Path(path).iterdir() if (p.name != FILENAME_METADATA) and (p.name != FILENAME_TYPELOOKUP)]\n        # Check that index values are unique\n        indices = [value[\"index\"] for value in metadata[\"elements\"].values()]\n        if len(indices) != len(set(indices)):\n            raise ValueError(\"Indices in metadata are not unique.\")\n        \n        elif metadata[\"library\"] == \"python\":\n            if not is_version_compatible(version=metadata[\"version\"], rules=PYTHON_VERSIONS_SUPPORTED):\n                raise ValueError(f\"Python version '{metadata['version']}' not supported for library 'python' and type '{metadata['type']}'. Version rules: {PYTHON_VERSIONS_SUPPORTED}\")\n        else:\n            raise ValueError(\"Only 'python' library supported for container types.\")\n        \n    ## Sort the element names by their index\n    names_meta_sorted = _sort_element_names_by_index(metadata=metadata, check=check)\n    names_allowed = set(names_meta_sorted) | set(NAMES_EXTRA_FILES_ALLOWED)\n\n    if check:\n        # Check that all elements in metadata are present in the folder and vice versa\n        if not all(name in names_path_elements for name in names_meta_sorted):\n            missing_elements = set(names_meta_sorted) - set(names_path_elements)\n            raise FileNotFoundError(f\"Elements in metadata not found in folder: {missing_elements}, names_meta: {names_meta_sorted}, names_path: {names_path_elements}, path: {path}\")\n        if not all(name in names_allowed for name in names_path_elements):\n            extra_elements = set(names_path_elements) - set(names_allowed)\n            raise ValueError(f\"Extra elements in folder not found in metadata: {extra_elements}\")        \n\n    ## Load each element in the order specified by the metadata index\n    elements = [load_element(\n        path=str(Path(path) / name),\n        metadata=metadata[\"elements\"][name],\n        type_lookup=type_lookup,\n        check=check,\n    ) for name in names_meta_sorted]\n    \n    if metadata[\"type\"] == \"list\":\n        pass\n    elif metadata[\"type\"] == \"tuple\":\n        elements = tuple(elements)\n    elif metadata[\"type\"] == \"set\":\n        elements = set(elements)\n    elif metadata[\"type\"] == \"frozenset\":\n        elements = frozenset(elements)\n    elif metadata[\"type\"] == \"dict_item\":\n        ## Make sure that there are exactly 2 elements\n        if check:\n            if len(elements) != 2:\n                raise ValueError(f\"DictItem must contain exactly 2 elements. Found {len(elements)}.\")\n        elements = DictItem(key=elements[0], value=elements[1])\n    else:  ## elif metadata[\"type\"] == \"dict\"\n        ## Make sure that all elements are DictItem types\n        if check:\n            if not all(isinstance(element, DictItem) for element in elements):\n                raise TypeError(\"All elements in a dict must be of type DictItem.\")\n        try:\n            elements = {element.key: element.value for element in elements}  ## Unpack the DictItems\n        except AttributeError as e:\n            raise ValueError(f\"Error unpacking dict items: {e}\")\n    \n    return elements\n", "function_save": "def save_container(\n    obj: Union[list, tuple, set, dict, frozenset, 'DictItem'],\n    path: Union[str, Path],\n    type_name: str,\n    type_lookup: Dict,\n    check: bool = True,\n    overwrite: bool = False,\n    name_dict_items: bool = True,\n) -> None:\n    \"\"\"\n    Saves a list, tuple, set, frozenset, or dict_item to the given directory.\n    \"\"\"\n    if isinstance(obj, dict):\n        _check_case_only_sibling_keys(obj=obj) if check and (name_dict_items) else None \n        obj = [DictItem(key=key, value=value) for key, value in obj.items()]\n\n    metadata_elements = {}\n    for idx, element in enumerate(obj):\n        try:\n            props = type_lookup[type(element)]\n            type_element = props[\"type_name\"]            \n        except TypeError as e:\n            raise TypeError(f\"Failed to get properties for element. \\n Directory: {path}. \\n Index: {idx}. \\n element: {element}. \\n type_name: {type_name}. \\n Error: {e}\")\n        name_element = f\"{idx}.{props['suffix']}\"  ## Make name the index and add suffix\n        if name_dict_items:\n            if type_element == \"dict_item\":\n                if isinstance(element.key, str):\n                    name_element = f\"{element.key}.{props['suffix']}\"\n            elif type_name == \"dict_item\":\n                name_element = f\"{['key', 'value'][idx]}.{props['suffix']}\"\n\n        _check_filename_safety(name=name_element, warn=True, raise_error=False)\n        path_element = str(Path(path) / name_element)  ## Make path\n        save_object(\n            obj=element,\n            path=path_element,\n            check=check,\n            overwrite=overwrite,\n            type_lookup=type_lookup,\n        )\n        metadata_elements[name_element] = {\n            \"type\": type_element,\n            \"library\": props[\"library\"],\n            \"version\": _get_library_version(library=props[\"library\"]),\n            \"index\": idx,\n        }\n\n    metadata_container = {\n        \"elements\": metadata_elements,\n        \"type\": type_name,\n        \"library\": \"python\",\n        \"version\": _get_python_version(),\n        \"version_richfile\": VERSION_RICHFILE,\n    }\n    save_metadata(\n        metadata=metadata_container,\n        path_dir=path,\n        check=check,\n        name_metadata=FILENAME_METADATA,\n        overwrite=overwrite,\n    )\n", "object_class": "<class 'tuple'>", "suffix": "tuple", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "set", "function_load": "def load_folder(\n    path: Union[str, Path],\n    type_lookup: Dict,\n    check: bool = True,\n    **kwargs,\n) -> Any:\n    \"\"\"\n    Loads the folder from the given path. Used for types: list, tuple, set, frozenset, dict.\n    \"\"\"\n    metadata = load_folder_metadata(path_dir=path, name_metadata=FILENAME_METADATA, check=check)\n\n    if check:\n        names_path_elements = [p.name for p in Path(path).iterdir() if (p.name != FILENAME_METADATA) and (p.name != FILENAME_TYPELOOKUP)]\n        # Check that index values are unique\n        indices = [value[\"index\"] for value in metadata[\"elements\"].values()]\n        if len(indices) != len(set(indices)):\n            raise ValueError(\"Indices in metadata are not unique.\")\n        \n        elif metadata[\"library\"] == \"python\":\n            if not is_version_compatible(version=metadata[\"version\"], rules=PYTHON_VERSIONS_SUPPORTED):\n                raise ValueError(f\"Python version '{metadata['version']}' not supported for library 'python' and type '{metadata['type']}'. Version rules: {PYTHON_VERSIONS_SUPPORTED}\")\n        else:\n            raise ValueError(\"Only 'python' library supported for container types.\")\n        \n    ## Sort the element names by their index\n    names_meta_sorted = _sort_element_names_by_index(metadata=metadata, check=check)\n    names_allowed = set(names_meta_sorted) | set(NAMES_EXTRA_FILES_ALLOWED)\n\n    if check:\n        # Check that all elements in metadata are present in the folder and vice versa\n        if not all(name in names_path_elements for name in names_meta_sorted):\n            missing_elements = set(names_meta_sorted) - set(names_path_elements)\n            raise FileNotFoundError(f\"Elements in metadata not found in folder: {missing_elements}, names_meta: {names_meta_sorted}, names_path: {names_path_elements}, path: {path}\")\n        if not all(name in names_allowed for name in names_path_elements):\n            extra_elements = set(names_path_elements) - set(names_allowed)\n            raise ValueError(f\"Extra elements in folder not found in metadata: {extra_elements}\")        \n\n    ## Load each element in the order specified by the metadata index\n    elements = [load_element(\n        path=str(Path(path) / name),\n        metadata=metadata[\"elements\"][name],\n        type_lookup=type_lookup,\n        check=check,\n    ) for name in names_meta_sorted]\n    \n    if metadata[\"type\"] == \"list\":\n        pass\n    elif metadata[\"type\"] == \"tuple\":\n        elements = tuple(elements)\n    elif metadata[\"type\"] == \"set\":\n        elements = set(elements)\n    elif metadata[\"type\"] == \"frozenset\":\n        elements = frozenset(elements)\n    elif metadata[\"type\"] == \"dict_item\":\n        ## Make sure that there are exactly 2 elements\n        if check:\n            if len(elements) != 2:\n                raise ValueError(f\"DictItem must contain exactly 2 elements. Found {len(elements)}.\")\n        elements = DictItem(key=elements[0], value=elements[1])\n    else:  ## elif metadata[\"type\"] == \"dict\"\n        ## Make sure that all elements are DictItem types\n        if check:\n            if not all(isinstance(element, DictItem) for element in elements):\n                raise TypeError(\"All elements in a dict must be of type DictItem.\")\n        try:\n            elements = {element.key: element.value for element in elements}  ## Unpack the DictItems\n        except AttributeError as e:\n            raise ValueError(f\"Error unpacking dict items: {e}\")\n    \n    return elements\n", "function_save": "def save_container(\n    obj: Union[list, tuple, set, dict, frozenset, 'DictItem'],\n    path: Union[str, Path],\n    type_name: str,\n    type_lookup: Dict,\n    check: bool = True,\n    overwrite: bool = False,\n    name_dict_items: bool = True,\n) -> None:\n    \"\"\"\n    Saves a list, tuple, set, frozenset, or dict_item to the given directory.\n    \"\"\"\n    if isinstance(obj, dict):\n        _check_case_only_sibling_keys(obj=obj) if check and (name_dict_items) else None \n        obj = [DictItem(key=key, value=value) for key, value in obj.items()]\n\n    metadata_elements = {}\n    for idx, element in enumerate(obj):\n        try:\n            props = type_lookup[type(element)]\n            type_element = props[\"type_name\"]            \n        except TypeError as e:\n            raise TypeError(f\"Failed to get properties for element. \\n Directory: {path}. \\n Index: {idx}. \\n element: {element}. \\n type_name: {type_name}. \\n Error: {e}\")\n        name_element = f\"{idx}.{props['suffix']}\"  ## Make name the index and add suffix\n        if name_dict_items:\n            if type_element == \"dict_item\":\n                if isinstance(element.key, str):\n                    name_element = f\"{element.key}.{props['suffix']}\"\n            elif type_name == \"dict_item\":\n                name_element = f\"{['key', 'value'][idx]}.{props['suffix']}\"\n\n        _check_filename_safety(name=name_element, warn=True, raise_error=False)\n        path_element = str(Path(path) / name_element)  ## Make path\n        save_object(\n            obj=element,\n            path=path_element,\n            check=check,\n            overwrite=overwrite,\n            type_lookup=type_lookup,\n        )\n        metadata_elements[name_element] = {\n            \"type\": type_element,\n            \"library\": props[\"library\"],\n            \"version\": _get_library_version(library=props[\"library\"]),\n            \"index\": idx,\n        }\n\n    metadata_container = {\n        \"elements\": metadata_elements,\n        \"type\": type_name,\n        \"library\": \"python\",\n        \"version\": _get_python_version(),\n        \"version_richfile\": VERSION_RICHFILE,\n    }\n    save_metadata(\n        metadata=metadata_container,\n        path_dir=path,\n        check=check,\n        name_metadata=FILENAME_METADATA,\n        overwrite=overwrite,\n    )\n", "object_class": "<class 'set'>", "suffix": "set", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "frozenset", "function_load": "def load_folder(\n    path: Union[str, Path],\n    type_lookup: Dict,\n    check: bool = True,\n    **kwargs,\n) -> Any:\n    \"\"\"\n    Loads the folder from the given path. Used for types: list, tuple, set, frozenset, dict.\n    \"\"\"\n    metadata = load_folder_metadata(path_dir=path, name_metadata=FILENAME_METADATA, check=check)\n\n    if check:\n        names_path_elements = [p.name for p in Path(path).iterdir() if (p.name != FILENAME_METADATA) and (p.name != FILENAME_TYPELOOKUP)]\n        # Check that index values are unique\n        indices = [value[\"index\"] for value in metadata[\"elements\"].values()]\n        if len(indices) != len(set(indices)):\n            raise ValueError(\"Indices in metadata are not unique.\")\n        \n        elif metadata[\"library\"] == \"python\":\n            if not is_version_compatible(version=metadata[\"version\"], rules=PYTHON_VERSIONS_SUPPORTED):\n                raise ValueError(f\"Python version '{metadata['version']}' not supported for library 'python' and type '{metadata['type']}'. Version rules: {PYTHON_VERSIONS_SUPPORTED}\")\n        else:\n            raise ValueError(\"Only 'python' library supported for container types.\")\n        \n    ## Sort the element names by their index\n    names_meta_sorted = _sort_element_names_by_index(metadata=metadata, check=check)\n    names_allowed = set(names_meta_sorted) | set(NAMES_EXTRA_FILES_ALLOWED)\n\n    if check:\n        # Check that all elements in metadata are present in the folder and vice versa\n        if not all(name in names_path_elements for name in names_meta_sorted):\n            missing_elements = set(names_meta_sorted) - set(names_path_elements)\n            raise FileNotFoundError(f\"Elements in metadata not found in folder: {missing_elements}, names_meta: {names_meta_sorted}, names_path: {names_path_elements}, path: {path}\")\n        if not all(name in names_allowed for name in names_path_elements):\n            extra_elements = set(names_path_elements) - set(names_allowed)\n            raise ValueError(f\"Extra elements in folder not found in metadata: {extra_elements}\")        \n\n    ## Load each element in the order specified by the metadata index\n    elements = [load_element(\n        path=str(Path(path) / name),\n        metadata=metadata[\"elements\"][name],\n        type_lookup=type_lookup,\n        check=check,\n    ) for name in names_meta_sorted]\n    \n    if metadata[\"type\"] == \"list\":\n        pass\n    elif metadata[\"type\"] == \"tuple\":\n        elements = tuple(elements)\n    elif metadata[\"type\"] == \"set\":\n        elements = set(elements)\n    elif metadata[\"type\"] == \"frozenset\":\n        elements = frozenset(elements)\n    elif metadata[\"type\"] == \"dict_item\":\n        ## Make sure that there are exactly 2 elements\n        if check:\n            if len(elements) != 2:\n                raise ValueError(f\"DictItem must contain exactly 2 elements. Found {len(elements)}.\")\n        elements = DictItem(key=elements[0], value=elements[1])\n    else:  ## elif metadata[\"type\"] == \"dict\"\n        ## Make sure that all elements are DictItem types\n        if check:\n            if not all(isinstance(element, DictItem) for element in elements):\n                raise TypeError(\"All elements in a dict must be of type DictItem.\")\n        try:\n            elements = {element.key: element.value for element in elements}  ## Unpack the DictItems\n        except AttributeError as e:\n            raise ValueError(f\"Error unpacking dict items: {e}\")\n    \n    return elements\n", "function_save": "def save_container(\n    obj: Union[list, tuple, set, dict, frozenset, 'DictItem'],\n    path: Union[str, Path],\n    type_name: str,\n    type_lookup: Dict,\n    check: bool = True,\n    overwrite: bool = False,\n    name_dict_items: bool = True,\n) -> None:\n    \"\"\"\n    Saves a list, tuple, set, frozenset, or dict_item to the given directory.\n    \"\"\"\n    if isinstance(obj, dict):\n        _check_case_only_sibling_keys(obj=obj) if check and (name_dict_items) else None \n        obj = [DictItem(key=key, value=value) for key, value in obj.items()]\n\n    metadata_elements = {}\n    for idx, element in enumerate(obj):\n        try:\n            props = type_lookup[type(element)]\n            type_element = props[\"type_name\"]            \n        except TypeError as e:\n            raise TypeError(f\"Failed to get properties for element. \\n Directory: {path}. \\n Index: {idx}. \\n element: {element}. \\n type_name: {type_name}. \\n Error: {e}\")\n        name_element = f\"{idx}.{props['suffix']}\"  ## Make name the index and add suffix\n        if name_dict_items:\n            if type_element == \"dict_item\":\n                if isinstance(element.key, str):\n                    name_element = f\"{element.key}.{props['suffix']}\"\n            elif type_name == \"dict_item\":\n                name_element = f\"{['key', 'value'][idx]}.{props['suffix']}\"\n\n        _check_filename_safety(name=name_element, warn=True, raise_error=False)\n        path_element = str(Path(path) / name_element)  ## Make path\n        save_object(\n            obj=element,\n            path=path_element,\n            check=check,\n            overwrite=overwrite,\n            type_lookup=type_lookup,\n        )\n        metadata_elements[name_element] = {\n            \"type\": type_element,\n            \"library\": props[\"library\"],\n            \"version\": _get_library_version(library=props[\"library\"]),\n            \"index\": idx,\n        }\n\n    metadata_container = {\n        \"elements\": metadata_elements,\n        \"type\": type_name,\n        \"library\": \"python\",\n        \"version\": _get_python_version(),\n        \"version_richfile\": VERSION_RICHFILE,\n    }\n    save_metadata(\n        metadata=metadata_container,\n        path_dir=path,\n        check=check,\n        name_metadata=FILENAME_METADATA,\n        overwrite=overwrite,\n    )\n", "object_class": "<class 'frozenset'>", "suffix": "frozenset", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "dict", "function_load": "def load_folder(\n    path: Union[str, Path],\n    type_lookup: Dict,\n    check: bool = True,\n    **kwargs,\n) -> Any:\n    \"\"\"\n    Loads the folder from the given path. Used for types: list, tuple, set, frozenset, dict.\n    \"\"\"\n    metadata = load_folder_metadata(path_dir=path, name_metadata=FILENAME_METADATA, check=check)\n\n    if check:\n        names_path_elements = [p.name for p in Path(path).iterdir() if (p.name != FILENAME_METADATA) and (p.name != FILENAME_TYPELOOKUP)]\n        # Check that index values are unique\n        indices = [value[\"index\"] for value in metadata[\"elements\"].values()]\n        if len(indices) != len(set(indices)):\n            raise ValueError(\"Indices in metadata are not unique.\")\n        \n        elif metadata[\"library\"] == \"python\":\n            if not is_version_compatible(version=metadata[\"version\"], rules=PYTHON_VERSIONS_SUPPORTED):\n                raise ValueError(f\"Python version '{metadata['version']}' not supported for library 'python' and type '{metadata['type']}'. Version rules: {PYTHON_VERSIONS_SUPPORTED}\")\n        else:\n            raise ValueError(\"Only 'python' library supported for container types.\")\n        \n    ## Sort the element names by their index\n    names_meta_sorted = _sort_element_names_by_index(metadata=metadata, check=check)\n    names_allowed = set(names_meta_sorted) | set(NAMES_EXTRA_FILES_ALLOWED)\n\n    if check:\n        # Check that all elements in metadata are present in the folder and vice versa\n        if not all(name in names_path_elements for name in names_meta_sorted):\n            missing_elements = set(names_meta_sorted) - set(names_path_elements)\n            raise FileNotFoundError(f\"Elements in metadata not found in folder: {missing_elements}, names_meta: {names_meta_sorted}, names_path: {names_path_elements}, path: {path}\")\n        if not all(name in names_allowed for name in names_path_elements):\n            extra_elements = set(names_path_elements) - set(names_allowed)\n            raise ValueError(f\"Extra elements in folder not found in metadata: {extra_elements}\")        \n\n    ## Load each element in the order specified by the metadata index\n    elements = [load_element(\n        path=str(Path(path) / name),\n        metadata=metadata[\"elements\"][name],\n        type_lookup=type_lookup,\n        check=check,\n    ) for name in names_meta_sorted]\n    \n    if metadata[\"type\"] == \"list\":\n        pass\n    elif metadata[\"type\"] == \"tuple\":\n        elements = tuple(elements)\n    elif metadata[\"type\"] == \"set\":\n        elements = set(elements)\n    elif metadata[\"type\"] == \"frozenset\":\n        elements = frozenset(elements)\n    elif metadata[\"type\"] == \"dict_item\":\n        ## Make sure that there are exactly 2 elements\n        if check:\n            if len(elements) != 2:\n                raise ValueError(f\"DictItem must contain exactly 2 elements. Found {len(elements)}.\")\n        elements = DictItem(key=elements[0], value=elements[1])\n    else:  ## elif metadata[\"type\"] == \"dict\"\n        ## Make sure that all elements are DictItem types\n        if check:\n            if not all(isinstance(element, DictItem) for element in elements):\n                raise TypeError(\"All elements in a dict must be of type DictItem.\")\n        try:\n            elements = {element.key: element.value for element in elements}  ## Unpack the DictItems\n        except AttributeError as e:\n            raise ValueError(f\"Error unpacking dict items: {e}\")\n    \n    return elements\n", "function_save": "def save_container(\n    obj: Union[list, tuple, set, dict, frozenset, 'DictItem'],\n    path: Union[str, Path],\n    type_name: str,\n    type_lookup: Dict,\n    check: bool = True,\n    overwrite: bool = False,\n    name_dict_items: bool = True,\n) -> None:\n    \"\"\"\n    Saves a list, tuple, set, frozenset, or dict_item to the given directory.\n    \"\"\"\n    if isinstance(obj, dict):\n        _check_case_only_sibling_keys(obj=obj) if check and (name_dict_items) else None \n        obj = [DictItem(key=key, value=value) for key, value in obj.items()]\n\n    metadata_elements = {}\n    for idx, element in enumerate(obj):\n        try:\n            props = type_lookup[type(element)]\n            type_element = props[\"type_name\"]            \n        except TypeError as e:\n            raise TypeError(f\"Failed to get properties for element. \\n Directory: {path}. \\n Index: {idx}. \\n element: {element}. \\n type_name: {type_name}. \\n Error: {e}\")\n        name_element = f\"{idx}.{props['suffix']}\"  ## Make name the index and add suffix\n        if name_dict_items:\n            if type_element == \"dict_item\":\n                if isinstance(element.key, str):\n                    name_element = f\"{element.key}.{props['suffix']}\"\n            elif type_name == \"dict_item\":\n                name_element = f\"{['key', 'value'][idx]}.{props['suffix']}\"\n\n        _check_filename_safety(name=name_element, warn=True, raise_error=False)\n        path_element = str(Path(path) / name_element)  ## Make path\n        save_object(\n            obj=element,\n            path=path_element,\n            check=check,\n            overwrite=overwrite,\n            type_lookup=type_lookup,\n        )\n        metadata_elements[name_element] = {\n            \"type\": type_element,\n            \"library\": props[\"library\"],\n            \"version\": _get_library_version(library=props[\"library\"]),\n            \"index\": idx,\n        }\n\n    metadata_container = {\n        \"elements\": metadata_elements,\n        \"type\": type_name,\n        \"library\": \"python\",\n        \"version\": _get_python_version(),\n        \"version_richfile\": VERSION_RICHFILE,\n    }\n    save_metadata(\n        metadata=metadata_container,\n        path_dir=path,\n        check=check,\n        name_metadata=FILENAME_METADATA,\n        overwrite=overwrite,\n    )\n", "object_class": "<class 'dict'>", "suffix": "dict", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "dict_item", "function_load": "def load_folder(\n    path: Union[str, Path],\n    type_lookup: Dict,\n    check: bool = True,\n    **kwargs,\n) -> Any:\n    \"\"\"\n    Loads the folder from the given path. Used for types: list, tuple, set, frozenset, dict.\n    \"\"\"\n    metadata = load_folder_metadata(path_dir=path, name_metadata=FILENAME_METADATA, check=check)\n\n    if check:\n        names_path_elements = [p.name for p in Path(path).iterdir() if (p.name != FILENAME_METADATA) and (p.name != FILENAME_TYPELOOKUP)]\n        # Check that index values are unique\n        indices = [value[\"index\"] for value in metadata[\"elements\"].values()]\n        if len(indices) != len(set(indices)):\n            raise ValueError(\"Indices in metadata are not unique.\")\n        \n        elif metadata[\"library\"] == \"python\":\n            if not is_version_compatible(version=metadata[\"version\"], rules=PYTHON_VERSIONS_SUPPORTED):\n                raise ValueError(f\"Python version '{metadata['version']}' not supported for library 'python' and type '{metadata['type']}'. Version rules: {PYTHON_VERSIONS_SUPPORTED}\")\n        else:\n            raise ValueError(\"Only 'python' library supported for container types.\")\n        \n    ## Sort the element names by their index\n    names_meta_sorted = _sort_element_names_by_index(metadata=metadata, check=check)\n    names_allowed = set(names_meta_sorted) | set(NAMES_EXTRA_FILES_ALLOWED)\n\n    if check:\n        # Check that all elements in metadata are present in the folder and vice versa\n        if not all(name in names_path_elements for name in names_meta_sorted):\n            missing_elements = set(names_meta_sorted) - set(names_path_elements)\n            raise FileNotFoundError(f\"Elements in metadata not found in folder: {missing_elements}, names_meta: {names_meta_sorted}, names_path: {names_path_elements}, path: {path}\")\n        if not all(name in names_allowed for name in names_path_elements):\n            extra_elements = set(names_path_elements) - set(names_allowed)\n            raise ValueError(f\"Extra elements in folder not found in metadata: {extra_elements}\")        \n\n    ## Load each element in the order specified by the metadata index\n    elements = [load_element(\n        path=str(Path(path) / name),\n        metadata=metadata[\"elements\"][name],\n        type_lookup=type_lookup,\n        check=check,\n    ) for name in names_meta_sorted]\n    \n    if metadata[\"type\"] == \"list\":\n        pass\n    elif metadata[\"type\"] == \"tuple\":\n        elements = tuple(elements)\n    elif metadata[\"type\"] == \"set\":\n        elements = set(elements)\n    elif metadata[\"type\"] == \"frozenset\":\n        elements = frozenset(elements)\n    elif metadata[\"type\"] == \"dict_item\":\n        ## Make sure that there are exactly 2 elements\n        if check:\n            if len(elements) != 2:\n                raise ValueError(f\"DictItem must contain exactly 2 elements. Found {len(elements)}.\")\n        elements = DictItem(key=elements[0], value=elements[1])\n    else:  ## elif metadata[\"type\"] == \"dict\"\n        ## Make sure that all elements are DictItem types\n        if check:\n            if not all(isinstance(element, DictItem) for element in elements):\n                raise TypeError(\"All elements in a dict must be of type DictItem.\")\n        try:\n            elements = {element.key: element.value for element in elements}  ## Unpack the DictItems\n        except AttributeError as e:\n            raise ValueError(f\"Error unpacking dict items: {e}\")\n    \n    return elements\n", "function_save": "def save_container(\n    obj: Union[list, tuple, set, dict, frozenset, 'DictItem'],\n    path: Union[str, Path],\n    type_name: str,\n    type_lookup: Dict,\n    check: bool = True,\n    overwrite: bool = False,\n    name_dict_items: bool = True,\n) -> None:\n    \"\"\"\n    Saves a list, tuple, set, frozenset, or dict_item to the given directory.\n    \"\"\"\n    if isinstance(obj, dict):\n        _check_case_only_sibling_keys(obj=obj) if check and (name_dict_items) else None \n        obj = [DictItem(key=key, value=value) for key, value in obj.items()]\n\n    metadata_elements = {}\n    for idx, element in enumerate(obj):\n        try:\n            props = type_lookup[type(element)]\n            type_element = props[\"type_name\"]            \n        except TypeError as e:\n            raise TypeError(f\"Failed to get properties for element. \\n Directory: {path}. \\n Index: {idx}. \\n element: {element}. \\n type_name: {type_name}. \\n Error: {e}\")\n        name_element = f\"{idx}.{props['suffix']}\"  ## Make name the index and add suffix\n        if name_dict_items:\n            if type_element == \"dict_item\":\n                if isinstance(element.key, str):\n                    name_element = f\"{element.key}.{props['suffix']}\"\n            elif type_name == \"dict_item\":\n                name_element = f\"{['key', 'value'][idx]}.{props['suffix']}\"\n\n        _check_filename_safety(name=name_element, warn=True, raise_error=False)\n        path_element = str(Path(path) / name_element)  ## Make path\n        save_object(\n            obj=element,\n            path=path_element,\n            check=check,\n            overwrite=overwrite,\n            type_lookup=type_lookup,\n        )\n        metadata_elements[name_element] = {\n            \"type\": type_element,\n            \"library\": props[\"library\"],\n            \"version\": _get_library_version(library=props[\"library\"]),\n            \"index\": idx,\n        }\n\n    metadata_container = {\n        \"elements\": metadata_elements,\n        \"type\": type_name,\n        \"library\": \"python\",\n        \"version\": _get_python_version(),\n        \"version_richfile\": VERSION_RICHFILE,\n    }\n    save_metadata(\n        metadata=metadata_container,\n        path_dir=path,\n        check=check,\n        name_metadata=FILENAME_METADATA,\n        overwrite=overwrite,\n    )\n", "object_class": "<class 'richfile.util.DictItem'>", "suffix": "dict_item", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "float", "function_load": "def load_float(path: Union[str, Path], **kwargs) -> float:\n    return float(load_json(path, **kwargs))\n", "function_save": "def save_json(\n    obj: Any,\n    path: Union[str, Path],\n    **kwargs,\n) -> None:\n    \"\"\"\n    Saves a JSON-serializable object to the given path.\n    \"\"\"\n    with open(path, \"w\") as f:\n        json.dump(obj, f)\n", "object_class": "<class 'float'>", "suffix": "json", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "int", "function_load": "def load_int(path: Union[str, Path], **kwargs) -> int:\n    return int(load_json(path, **kwargs))\n", "function_save": "def save_json(\n    obj: Any,\n    path: Union[str, Path],\n    **kwargs,\n) -> None:\n    \"\"\"\n    Saves a JSON-serializable object to the given path.\n    \"\"\"\n    with open(path, \"w\") as f:\n        json.dump(obj, f)\n", "object_class": "<class 'int'>", "suffix": "json", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "str", "function_load": "def load_str(path: Union[str, Path], **kwargs) -> str:\n    return str(load_json(path, **kwargs))\n", "function_save": "def save_json(\n    obj: Any,\n    path: Union[str, Path],\n    **kwargs,\n) -> None:\n    \"\"\"\n    Saves a JSON-serializable object to the given path.\n    \"\"\"\n    with open(path, \"w\") as f:\n        json.dump(obj, f)\n", "object_class": "<class 'str'>", "suffix": "json", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "bool", "function_load": "def load_bool(path: Union[str, Path], **kwargs) -> bool:\n    return bool(load_json(path, **kwargs))\n", "function_save": "def save_json(\n    obj: Any,\n    path: Union[str, Path],\n    **kwargs,\n) -> None:\n    \"\"\"\n    Saves a JSON-serializable object to the given path.\n    \"\"\"\n    with open(path, \"w\") as f:\n        json.dump(obj, f)\n", "object_class": "<class 'bool'>", "suffix": "json", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "None", "function_load": "def load_None(path: Union[str, Path], **kwargs) -> None:\n    out = load_json(path, **kwargs)\n    if out is not None:\n        raise ValueError(\"Loaded object is not None.\")\n    return out\n", "function_save": "def save_json(\n    obj: Any,\n    path: Union[str, Path],\n    **kwargs,\n) -> None:\n    \"\"\"\n    Saves a JSON-serializable object to the given path.\n    \"\"\"\n    with open(path, \"w\") as f:\n        json.dump(obj, f)\n", "object_class": "<class 'NoneType'>", "suffix": "json", "library": "python", "versions_supported": [">=3", "<4"]}, {"type_name": "numpy_array", "function_load": "        def load_npy_array(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> np.ndarray:\n            \"\"\"\n            Loads an array from the given path.\n            \"\"\"    \n            return np.load(path, **kwargs)\n", "function_save": "        def save_npy_array(\n            obj: np.ndarray,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves a NumPy array to the given path.\n            \"\"\"\n            np.save(path, obj, **kwargs)\n", "object_class": "<class 'numpy.ndarray'>", "suffix": "npy", "library": "numpy", "versions_supported": []}, {"type_name": "numpy_scalar", "function_load": "        def load_npy_array(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> np.ndarray:\n            \"\"\"\n            Loads an array from the given path.\n            \"\"\"    \n            return np.load(path, **kwargs)\n", "function_save": "        def save_npy_array(\n            obj: np.ndarray,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves a NumPy array to the given path.\n            \"\"\"\n            np.save(path, obj, **kwargs)\n", "object_class": "<class 'numpy.number'>", "suffix": "npy", "library": "numpy", "versions_supported": []}, {"type_name": "scipy_sparse_array", "function_load": "        def load_sparse_array(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> scipy.sparse.csr_matrix:\n            \"\"\"\n            Loads a sparse array from the given path.\n            \"\"\"        \n            return scipy.sparse.load_npz(path, **kwargs)\n", "function_save": "        def save_sparse_array(\n            obj: scipy.sparse.spmatrix,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves a SciPy sparse matrix to the given path.\n            \"\"\"\n            scipy.sparse.save_npz(path, obj, **kwargs)\n", "object_class": "<class 'scipy.sparse._matrix.spmatrix'>", "suffix": "npz", "library": "scipy", "versions_supported": []}, {"type_name": "json_dict", "function_load": "        def load_json_dict(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> collections.UserDict:\n            \"\"\"\n            Loads a dictionary from the given path.\n            \"\"\"\n            with open(path, 'r') as f:\n                return JSON_Dict(json.load(f, **kwargs))\n", "function_save": "        def save_json_dict(\n            obj: collections.UserDict,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves a dictionary to the given path.\n            \"\"\"\n            with open(path, 'w') as f:\n                json.dump(dict(obj), f, **kwargs)\n", "object_class": "<class 'roicat.util.JSON_Dict'>", "suffix": "json", "library": "python", "versions_supported": []}, {"type_name": "json_list", "function_load": "        def load_json_list(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> collections.UserList:\n            \"\"\"\n            Loads a list from the given path.\n            \"\"\"\n            with open(path, 'r') as f:\n                return JSON_List(json.load(f, **kwargs))\n", "function_save": "        def save_json_list(\n            obj: collections.UserList,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves a list to the given path.\n            \"\"\"\n            with open(path, 'w') as f:\n                json.dump(list(obj), f, **kwargs)\n", "object_class": "<class 'roicat.util.JSON_List'>", "suffix": "json", "library": "python", "versions_supported": []}, {"type_name": "optuna_study", "function_load": "        def load_optuna_study(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> optuna.study.Study:\n            \"\"\"\n            Loads an Optuna study from the given path.\n            \"\"\"\n            with open(path, 'rb') as f:\n                return pickle.load(f, **kwargs)\n", "function_save": "        def save_optuna_study(\n            obj: optuna.study.Study,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves an Optuna study to the given path.\n            \"\"\"\n            with open(path, 'wb') as f:\n                pickle.dump(obj, f, **kwargs)\n", "object_class": "<class 'optuna.study.study.Study'>", "suffix": "optuna", "library": "optuna", "versions_supported": []}, {"type_name": "torch_tensor", "function_load": "        def load_torch_tensor(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> torch.Tensor:\n            \"\"\"\n            Loads a PyTorch tensor from the given path.\n            \"\"\"\n            return torch.from_numpy(np.load(path, **kwargs))\n", "function_save": "        def save_torch_tensor(\n            obj: torch.Tensor,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves a PyTorch tensor to the given path as a NumPy array.\n            \"\"\"\n            np.save(path, obj.detach().cpu().numpy(), **kwargs)\n", "object_class": "<class 'torch.Tensor'>", "suffix": "npy", "library": "torch", "versions_supported": []}, {"type_name": "model_swt", "function_load": "        def load_repr(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> object:\n            \"\"\"\n            Loads the repr of an object from the given path.\n            \"\"\"\n            with open(path, 'r') as f:\n                return f.read()\n", "function_save": "        def save_repr(\n            obj: object,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves the repr of an object to the given path.\n            \"\"\"\n            with open(path, 'w') as f:\n                f.write(repr(obj))\n", "object_class": "<class 'roicat.util.Model_SWT'>", "suffix": "swt", "library": "onnx2torch", "versions_supported": []}, {"type_name": "torch_module", "function_load": "        def load_repr(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> object:\n            \"\"\"\n            Loads the repr of an object from the given path.\n            \"\"\"\n            with open(path, 'r') as f:\n                return f.read()\n", "function_save": "        def save_repr(\n            obj: object,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves the repr of an object to the given path.\n            \"\"\"\n            with open(path, 'w') as f:\n                f.write(repr(obj))\n", "object_class": "<class 'torch.nn.modules.module.Module'>", "suffix": "torch_module", "library": "torch", "versions_supported": []}, {"type_name": "torch_sequence", "function_load": "        def load_repr(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> object:\n            \"\"\"\n            Loads the repr of an object from the given path.\n            \"\"\"\n            with open(path, 'r') as f:\n                return f.read()\n", "function_save": "        def save_repr(\n            obj: object,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves the repr of an object to the given path.\n            \"\"\"\n            with open(path, 'w') as f:\n                f.write(repr(obj))\n", "object_class": "<class 'torch.nn.modules.container.Sequential'>", "suffix": "torch_sequence", "library": "torch", "versions_supported": []}, {"type_name": "torch_dataset", "function_load": "        def load_repr(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> object:\n            \"\"\"\n            Loads the repr of an object from the given path.\n            \"\"\"\n            with open(path, 'r') as f:\n                return f.read()\n", "function_save": "        def save_repr(\n            obj: object,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves the repr of an object to the given path.\n            \"\"\"\n            with open(path, 'w') as f:\n                f.write(repr(obj))\n", "object_class": "<class 'torch.utils.data.dataset.Dataset'>", "suffix": "torch_dataset", "library": "torch", "versions_supported": []}, {"type_name": "torch_dataloader", "function_load": "        def load_repr(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> object:\n            \"\"\"\n            Loads the repr of an object from the given path.\n            \"\"\"\n            with open(path, 'r') as f:\n                return f.read()\n", "function_save": "        def save_repr(\n            obj: object,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves the repr of an object to the given path.\n            \"\"\"\n            with open(path, 'w') as f:\n                f.write(repr(obj))\n", "object_class": "<class 'torch.utils.data.dataloader.DataLoader'>", "suffix": "torch_dataloader", "library": "torch", "versions_supported": []}, {"type_name": "hdbscan", "function_load": "        def load_repr(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> object:\n            \"\"\"\n            Loads the repr of an object from the given path.\n            \"\"\"\n            with open(path, 'r') as f:\n                return f.read()\n", "function_save": "        def save_repr(\n            obj: object,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves the repr of an object to the given path.\n            \"\"\"\n            with open(path, 'w') as f:\n                f.write(repr(obj))\n", "object_class": "<class 'hdbscan.hdbscan_.HDBSCAN'>", "suffix": "hdbscan", "library": "torch", "versions_supported": []}, {"type_name": "pandas_dataframe", "function_load": "        def load_pandas_dataframe(\n            path: Union[str, Path],\n            **kwargs,\n        ) -> pd.DataFrame:\n            \"\"\"\n            Loads a Pandas DataFrame from the given path.\n            \"\"\"\n            ## Load as a CSV file\n            return pd.read_csv(path, index_col=0, **kwargs)\n", "function_save": "        def save_pandas_dataframe(\n            obj: pd.DataFrame,\n            path: Union[str, Path],\n            **kwargs,\n        ) -> None:\n            \"\"\"\n            Saves a Pandas DataFrame to the given path.\n            \"\"\"\n            ## Save as a CSV file\n            obj.to_csv(path, index=True, **kwargs)\n", "object_class": "<class 'pandas.core.frame.DataFrame'>", "suffix": "csv", "library": "pandas", "versions_supported": []}, {"type_name": "toeplitz_conv", "function_load": "    def function_load(\n        self,\n        path: Union[str, Path],\n        type_lookup: Dict,\n        check: bool = True,\n        **kwargs,\n    ) -> Any:\n        \"\"\"\n        Loads an object from the given path.\n        \"\"\"\n        out = self.object_class.__new__(self.object_class)\n        out.__dict__ = util.load_folder(\n            path=path,\n            type_lookup=type_lookup,\n            check=check,\n            **kwargs,\n        )\n        return out\n", "function_save": "    def function_save(\n        self,\n        obj: Any,\n        path: Union[str, Path],\n        type_lookup: Dict,\n        check: bool = True,\n        overwrite: bool = False,\n        name_dict_items: bool = True,\n        **kwargs,\n    ) -> None:\n        \"\"\"\n        Saves an object to the given path as a container.\n        \"\"\"\n        if not isinstance(obj, self.object_class):\n            raise TypeError(f\"Object must be of type {self.object_class}.\")\n        \n        util.save_container(\n            obj=obj.__dict__,\n            path=path,\n            type_name=self.type_name,\n            type_lookup=type_lookup,\n            check=check,\n            overwrite=overwrite,\n            name_dict_items=name_dict_items,\n        )\n", "object_class": "<class 'roicat.helpers.Toeplitz_convolution2d'>", "suffix": "roicat", "library": "roicat", "versions_supported": [">=1.1", "<2"]}, {"type_name": "convergence_checker_optuna", "function_load": "    def function_load(\n        self,\n        path: Union[str, Path],\n        type_lookup: Dict,\n        check: bool = True,\n        **kwargs,\n    ) -> Any:\n        \"\"\"\n        Loads an object from the given path.\n        \"\"\"\n        out = self.object_class.__new__(self.object_class)\n        out.__dict__ = util.load_folder(\n            path=path,\n            type_lookup=type_lookup,\n            check=check,\n            **kwargs,\n        )\n        return out\n", "function_save": "    def function_save(\n        self,\n        obj: Any,\n        path: Union[str, Path],\n        type_lookup: Dict,\n        check: bool = True,\n        overwrite: bool = False,\n        name_dict_items: bool = True,\n        **kwargs,\n    ) -> None:\n        \"\"\"\n        Saves an object to the given path as a container.\n        \"\"\"\n        if not isinstance(obj, self.object_class):\n            raise TypeError(f\"Object must be of type {self.object_class}.\")\n        \n        util.save_container(\n            obj=obj.__dict__,\n            path=path,\n            type_name=self.type_name,\n            type_lookup=type_lookup,\n            check=check,\n            overwrite=overwrite,\n            name_dict_items=name_dict_items,\n        )\n", "object_class": "<class 'roicat.helpers.Convergence_checker_optuna'>", "suffix": "roicat", "library": "roicat", "versions_supported": [">=1.1", "<2"]}, {"type_name": "image_alignment_checker", "function_load": "    def function_load(\n        self,\n        path: Union[str, Path],\n        type_lookup: Dict,\n        check: bool = True,\n        **kwargs,\n    ) -> Any:\n        \"\"\"\n        Loads an object from the given path.\n        \"\"\"\n        out = self.object_class.__new__(self.object_class)\n        out.__dict__ = util.load_folder(\n            path=path,\n            type_lookup=type_lookup,\n            check=check,\n            **kwargs,\n        )\n        return out\n", "function_save": "    def function_save(\n        self,\n        obj: Any,\n        path: Union[str, Path],\n        type_lookup: Dict,\n        check: bool = True,\n        overwrite: bool = False,\n        name_dict_items: bool = True,\n        **kwargs,\n    ) -> None:\n        \"\"\"\n        Saves an object to the given path as a container.\n        \"\"\"\n        if not isinstance(obj, self.object_class):\n            raise TypeError(f\"Object must be of type {self.object_class}.\")\n        \n        util.save_container(\n            obj=obj.__dict__,\n            path=path,\n            type_name=self.type_name,\n            type_lookup=type_lookup,\n            check=check,\n            overwrite=overwrite,\n            name_dict_items=name_dict_items,\n        )\n", "object_class": "<class 'roicat.helpers.ImageAlignmentChecker'>", "suffix": "roicat", "library": "roicat", "versions_supported": [">=1.1", "<2"]}]